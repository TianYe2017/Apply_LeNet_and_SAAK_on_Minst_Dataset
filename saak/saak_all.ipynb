{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libs\n",
    "import torch\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data.datasets import MNIST\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saak_feature_cluster_train=[]\n",
    "saak_feature_cluster_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0_3\n"
     ]
    }
   ],
   "source": [
    "print (torch.__version__)\n",
    "batch_size=1\n",
    "test_batch_size=1\n",
    "kwargs={}\n",
    "train_loader=data_utils.DataLoader(MNIST(root='./data',train=True,process=False,transform=transforms.Compose([\n",
    "    transforms.Scale((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "])),batch_size=batch_size,shuffle=True,**kwargs)\n",
    "\n",
    "\n",
    "test_loader=data_utils.DataLoader(MNIST(root='./data',train=False,process=False,transform=transforms.Compose([\n",
    "    transforms.Scale((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "])),batch_size=test_batch_size,shuffle=True,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_train_dataset():\n",
    "    datasets = []\n",
    "    train_label = []\n",
    "    for data in train_loader:\n",
    "        data_numpy = data[0].numpy()\n",
    "        label_numpy = data[1].numpy()\n",
    "        data_numpy = np.squeeze(data_numpy)\n",
    "        datasets.append(data_numpy)\n",
    "        train_label.append(label_numpy)\n",
    "\n",
    "    datasets = np.array(datasets)\n",
    "    datasets=np.expand_dims(datasets,axis=1)\n",
    "    print ('Numpy train dataset shape is {}'.format(datasets.shape))\n",
    "    return datasets,train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_test_dataset():\n",
    "    datasets = []\n",
    "    test_label = []\n",
    "    for data in test_loader:\n",
    "        data_numpy = data[0].numpy()\n",
    "        label_numpy = data[1].numpy()\n",
    "        data_numpy = np.squeeze(data_numpy)\n",
    "        datasets.append(data_numpy)\n",
    "        test_label.append(label_numpy)\n",
    "\n",
    "    datasets = np.array(datasets)\n",
    "    datasets=np.expand_dims(datasets,axis=1)\n",
    "    print ('Numpy test dataset shape is {}'.format(datasets.shape))\n",
    "    return datasets,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_and_augment(data_in, num_key_comp):\n",
    "    # data reshape\n",
    "    data=np.reshape(data_in,(data_in.shape[0],-1))\n",
    "    print ('PCA_and_augment: {}'.format(data.shape))\n",
    "    # mean removal\n",
    "    mean = np.mean(data, axis=0)\n",
    "    datas_mean_remov = data - mean\n",
    "    print ('PCA_and_augment meanremove shape: {}'.format(datas_mean_remov.shape))\n",
    "\n",
    "    # PCA, retain all components\n",
    "    #pca=PCA(n_components = num_key_comp)\n",
    "    pca=PCA(n_components=num_key_comp)\n",
    "    pca.fit(datas_mean_remov)\n",
    "    \n",
    "    #eng=np.cumsum(pca.explained_variance_ratio_)\n",
    "    #f_num = np.count_nonzero(eng < 0.999)\n",
    "    #comps=pca.components_[:f_num,:]\n",
    "    comps=pca.components_\n",
    "    \n",
    "    # augment, DC component doesn't\n",
    "    comps_aug=[vec*(-1) for vec in comps[:-1]]\n",
    "    comps_complete=np.vstack((comps,comps_aug))\n",
    "    print ('PCA_and_augment comps_complete shape: {}'.format(comps_complete.shape))\n",
    "    return comps_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def fit_pca_shape(datasets,depth):\n",
    "    factor=np.power(2,depth)\n",
    "    length=32/factor\n",
    "    print ('fit_pca_shape: length: {}'.format(length))\n",
    "    idx1=range(0,int(length),2)\n",
    "    idx2=[i+2 for i in idx1]\n",
    "    print ('fit_pca_shape: idx1: {}'.format(idx1))\n",
    "    data_lattice=[datasets[:,:,i:j,k:l] for ((i,j),(k,l)) in product(zip(idx1,idx2),zip(idx1,idx2))]\n",
    "    data_lattice=np.array(data_lattice)\n",
    "    print ('fit_pca_shape: data_lattice.shape: {}'.format(data_lattice.shape))\n",
    "\n",
    "    #shape reshape\n",
    "    data=np.reshape(data_lattice,(data_lattice.shape[0]*data_lattice.shape[1],data_lattice.shape[2],2,2))\n",
    "    print ('fit_pca_shape: reshape: {}'.format(data.shape))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_filt_patches(aug_anchors,input_channels):\n",
    "    shape=int(aug_anchors.shape[1]/4)\n",
    "    num=int(aug_anchors.shape[0])\n",
    "    filt=np.reshape(aug_anchors,(num,shape,4))\n",
    "    \n",
    "    # reshape to kernels, (# output_channels,# input_channels,2,2)\n",
    "    filters=np.reshape(filt,(num,shape,2,2))\n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_and_relu(filters,datasets,stride=2):\n",
    "    # torch data change\n",
    "    filters_t=torch.from_numpy(filters)\n",
    "    datasets_t=torch.from_numpy(datasets)\n",
    "\n",
    "    # Variables\n",
    "    filt=Variable(filters_t).type(torch.FloatTensor)\n",
    "    data=Variable(datasets_t).type(torch.FloatTensor)\n",
    "\n",
    "    # Convolution\n",
    "    output=F.conv2d(data,filt,stride=stride)\n",
    "\n",
    "    # Relu\n",
    "    relu_output=F.relu(output)\n",
    "\n",
    "    return relu_output,filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_stage_saak_trans(datasets=None,depth=0,num_key_comp=[5,5,5,5,5]):\n",
    "\n",
    "    # intial dataset, (60000,1,32,32)\n",
    "    # channel change: 1->7\n",
    "    print ('one_stage_saak_trans: datasets.shape {}'.format(datasets.shape))\n",
    "    input_channels=datasets.shape[1]\n",
    "\n",
    "    # change data shape, (14*60000,4)\n",
    "    data_flatten=fit_pca_shape(datasets,depth)\n",
    "    \n",
    "    # augmented components, first round: (7,4), only augment AC components\n",
    "    comps_complete=PCA_and_augment(data_flatten,num_key_comp)\n",
    "    print ('one_stage_saak_trans: comps_complete: {}'.format(comps_complete.shape))\n",
    "\n",
    "    # get filter, (7,1,2,2) \n",
    "    filters=ret_filt_patches(comps_complete,input_channels)\n",
    "    print ('one_stage_saak_trans: filters: {}'.format(filters.shape))\n",
    "\n",
    "    # output (60000,7,14,14)\n",
    "    relu_output,filt=conv_and_relu(filters,datasets,stride=2)\n",
    "\n",
    "    data=relu_output.data.numpy()\n",
    "    print ('one_stage_saak_trans: output: {}'.format(data.shape))\n",
    "    return data,filt,relu_output,filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_stage_saak_trans():\n",
    "    filters = []\n",
    "    saak_train=[]\n",
    "    saak_test=[]\n",
    "    \n",
    "    data_train,train_label=create_all_train_dataset()\n",
    "    data_test,test_label = create_all_test_dataset()\n",
    "    original_train_dataset=data_train\n",
    "    original_test_dataset=data_test\n",
    "    \n",
    "    num_key_comp = [3,4,7,6,8]\n",
    "    \n",
    "    for i in range(5):\n",
    "        print ('{} stage of saak transform_train: '.format(i))      \n",
    "        data_train,filt,output,f=one_stage_saak_trans(data_train,depth=i,num_key_comp=num_key_comp[i])\n",
    "        filters.append(f)\n",
    "        saak_train.append(data_train)\n",
    "    for i in range(5):\n",
    "        print ('{} stage of saak transform_test: '.format(i))\n",
    "        relu_output,filt=conv_and_relu(filters[i],data_test,stride=2)\n",
    "        data_test=relu_output.data.numpy()\n",
    "        saak_test.append(data_test)\n",
    "    \n",
    "    saak_train_data=saak_train[0].reshape((60000,-1))\n",
    "    saak_train_data=np.concatenate((saak_train_data,saak_train[1].reshape((60000,-1))),axis=1)\n",
    "    saak_train_data=np.concatenate((saak_train_data,saak_train[2].reshape((60000,-1))),axis=1)\n",
    "    saak_train_data=np.concatenate((saak_train_data,saak_train[3].reshape((60000,-1))),axis=1)\n",
    "    saak_train_data=np.concatenate((saak_train_data,saak_train[4].reshape((60000,-1))),axis=1)\n",
    "    #print (\"shape of train data is: \" + saak_train_data.shape)\n",
    "    saak_test_data=saak_test[0].reshape((10000,-1))\n",
    "    saak_test_data=np.concatenate((saak_test_data,saak_test[1].reshape((10000,-1))),axis=1)\n",
    "    saak_test_data=np.concatenate((saak_test_data,saak_test[2].reshape((10000,-1))),axis=1)\n",
    "    saak_test_data=np.concatenate((saak_test_data,saak_test[3].reshape((10000,-1))),axis=1)\n",
    "    saak_test_data=np.concatenate((saak_test_data,saak_test[4].reshape((10000,-1))),axis=1)\n",
    "    #print (\"shape of test data is: \" + saak_test_data.shape)\n",
    "           \n",
    "    return saak_train_data,saak_test_data,train_label,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy train dataset shape is (60000, 1, 32, 32)\n",
      "Numpy test dataset shape is (10000, 1, 32, 32)\n",
      "0 stage of saak transform_train: \n",
      "one_stage_saak_trans: datasets.shape (60000, 1, 32, 32)\n",
      "fit_pca_shape: length: 32.0\n",
      "fit_pca_shape: idx1: range(0, 32, 2)\n",
      "fit_pca_shape: data_lattice.shape: (256, 60000, 1, 2, 2)\n",
      "fit_pca_shape: reshape: (15360000, 1, 2, 2)\n",
      "PCA_and_augment: (15360000, 4)\n",
      "PCA_and_augment meanremove shape: (15360000, 4)\n",
      "PCA_and_augment comps_complete shape: (5, 4)\n",
      "one_stage_saak_trans: comps_complete: (5, 4)\n",
      "one_stage_saak_trans: filters: (5, 1, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 5, 16, 16)\n",
      "1 stage of saak transform_train: \n",
      "one_stage_saak_trans: datasets.shape (60000, 5, 16, 16)\n",
      "fit_pca_shape: length: 16.0\n",
      "fit_pca_shape: idx1: range(0, 16, 2)\n",
      "fit_pca_shape: data_lattice.shape: (64, 60000, 5, 2, 2)\n",
      "fit_pca_shape: reshape: (3840000, 5, 2, 2)\n",
      "PCA_and_augment: (3840000, 20)\n",
      "PCA_and_augment meanremove shape: (3840000, 20)\n",
      "PCA_and_augment comps_complete shape: (7, 20)\n",
      "one_stage_saak_trans: comps_complete: (7, 20)\n",
      "one_stage_saak_trans: filters: (7, 5, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 7, 8, 8)\n",
      "2 stage of saak transform_train: \n",
      "one_stage_saak_trans: datasets.shape (60000, 7, 8, 8)\n",
      "fit_pca_shape: length: 8.0\n",
      "fit_pca_shape: idx1: range(0, 8, 2)\n",
      "fit_pca_shape: data_lattice.shape: (16, 60000, 7, 2, 2)\n",
      "fit_pca_shape: reshape: (960000, 7, 2, 2)\n",
      "PCA_and_augment: (960000, 28)\n",
      "PCA_and_augment meanremove shape: (960000, 28)\n",
      "PCA_and_augment comps_complete shape: (13, 28)\n",
      "one_stage_saak_trans: comps_complete: (13, 28)\n",
      "one_stage_saak_trans: filters: (13, 7, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 13, 4, 4)\n",
      "3 stage of saak transform_train: \n",
      "one_stage_saak_trans: datasets.shape (60000, 13, 4, 4)\n",
      "fit_pca_shape: length: 4.0\n",
      "fit_pca_shape: idx1: range(0, 4, 2)\n",
      "fit_pca_shape: data_lattice.shape: (4, 60000, 13, 2, 2)\n",
      "fit_pca_shape: reshape: (240000, 13, 2, 2)\n",
      "PCA_and_augment: (240000, 52)\n",
      "PCA_and_augment meanremove shape: (240000, 52)\n",
      "PCA_and_augment comps_complete shape: (11, 52)\n",
      "one_stage_saak_trans: comps_complete: (11, 52)\n",
      "one_stage_saak_trans: filters: (11, 13, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 11, 2, 2)\n",
      "4 stage of saak transform_train: \n",
      "one_stage_saak_trans: datasets.shape (60000, 11, 2, 2)\n",
      "fit_pca_shape: length: 2.0\n",
      "fit_pca_shape: idx1: range(0, 2, 2)\n",
      "fit_pca_shape: data_lattice.shape: (1, 60000, 11, 2, 2)\n",
      "fit_pca_shape: reshape: (60000, 11, 2, 2)\n",
      "PCA_and_augment: (60000, 44)\n",
      "PCA_and_augment meanremove shape: (60000, 44)\n",
      "PCA_and_augment comps_complete shape: (15, 44)\n",
      "one_stage_saak_trans: comps_complete: (15, 44)\n",
      "one_stage_saak_trans: filters: (15, 11, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 15, 1, 1)\n",
      "0 stage of saak transform_test: \n",
      "1 stage of saak transform_test: \n",
      "2 stage of saak transform_test: \n",
      "3 stage of saak transform_test: \n",
      "4 stage of saak transform_test: \n"
     ]
    }
   ],
   "source": [
    "saak_trainm,saak_testm,train_label,test_label=five_stage_saak_trans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1995)\n",
      "(10000, 1995)\n",
      "(60000, 1995)\n",
      "(10000, 1995)\n"
     ]
    }
   ],
   "source": [
    "print(saak_trainm.shape)\n",
    "print(saak_testm.shape)\n",
    "#print(saak_train[0])\n",
    "saak_trainm = saak_trainm.reshape((60000,-1))\n",
    "saak_testm = saak_testm.reshape((10000,-1))\n",
    "print(saak_trainm.shape)\n",
    "print(saak_testm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/tian/.local/lib/python3.5/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [   0    1   14   15   16  224  240  255  256  257  270  271  272  287  479\n",
      "  480  495  496  509  510  511  512  513  526  527  528  544  720  736  752\n",
      "  753  754  766  767  768  769  770  771  772  773  774  775  776  777  778\n",
      "  779  780  781  782  783  784  785  786  787  788  789  790  791  792  793\n",
      "  794  795  796  797  798  799  800  801  802  803  804  805  806  807  808\n",
      "  809  810  811  812  813  814  815  816  817  818  819  820  821  822  823\n",
      "  824  825  826  827  828  829  830  831  832  833  834  835  836  837  838\n",
      "  839  840  841  842  843  844  845  846  847  848  849  850  851  852  853\n",
      "  854  855  856  857  858  859  860  861  862  863  864  865  866  867  868\n",
      "  869  870  871  872  873  874  875  876  877  878  879  880  881  882  883\n",
      "  884  885  886  887  888  889  890  891  892  893  894  895  896  897  898\n",
      "  899  900  901  902  903  904  905  906  907  908  909  910  911  912  913\n",
      "  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928\n",
      "  929  930  931  932  933  934  935  936  937  938  939  940  941  942  943\n",
      "  944  945  946  947  948  949  950  951  952  953  954  955  956  957  958\n",
      "  959  960  961  962  963  964  965  966  967  968  969  970  971  972  973\n",
      "  974  975  976  977  978  979  980  981  982  983  984  985  986  987  988\n",
      "  989  990  991  992  993  994  995  996  997  998  999 1000 1001 1002 1003\n",
      " 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018\n",
      " 1019 1020 1021 1022 1023 1024 1025 1026 1028 1038 1039 1040 1041 1056 1072\n",
      " 1088 1248 1264 1265 1279 1407 1464 1479 1536 1537 1538 1539 1540 1541 1542\n",
      " 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557\n",
      " 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572\n",
      " 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587\n",
      " 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1664 1671\n",
      " 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854\n",
      " 1855 1975 1988] are constant.\n",
      "  UserWarning)\n",
      "/home/tian/.local/lib/python3.5/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1000)\n",
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "fvalue_selector = SelectKBest(f_classif, k=1000)\n",
    "saak_trainm = fvalue_selector.fit_transform(saak_trainm,train_label)\n",
    "saak_testm = fvalue_selector.transform(saak_testm)\n",
    "print(saak_trainm.shape)\n",
    "print(saak_testm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 64)\n",
      "(10000, 64)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 64)\n",
    "saak_trainm = pca.fit_transform(saak_trainm)\n",
    "saak_testm = pca.transform(saak_testm)\n",
    "\n",
    "print(saak_trainm.shape)\n",
    "print(saak_testm.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1509\n"
     ]
    }
   ],
   "source": [
    "print(str(4*256+5*64+8*16+7*4+9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train = SVC(\n",
    "          C=1.0,\n",
    "          cache_size=200,\n",
    "          class_weight=None,\n",
    "          coef0=0.0,\n",
    "          decision_function_shape='ovr',\n",
    "          degree=3,\n",
    "          gamma='auto', \n",
    "          kernel='rbf',\n",
    "          max_iter=2000,\n",
    "          probability=False, \n",
    "          random_state=None, \n",
    "          shrinking=True,\n",
    "          tol=0.001,\n",
    "          verbose=False,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/tian/.local/lib/python3.5/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=2000, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train.fit(saak_trainm,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = svm_train.predict(saak_trainm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = svm_train.predict(saak_testm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of correct classification_train: 59789\n",
      "accuray_train: 0.9964833333333334\n",
      "num of correct classification_test: 9840\n",
      "accuray_test: 0.984\n"
     ]
    }
   ],
   "source": [
    "accuray = 0\n",
    "for i in range(60000):\n",
    "    if train_label[i]==train_result[i]:\n",
    "        accuray = accuray + 1\n",
    "print(\"num of correct classification_train: \" + str(accuray))\n",
    "print(\"accuray_train: \" + str(accuray/60000.0))\n",
    "accuray = 0\n",
    "for i in range(10000):\n",
    "    if test_label[i]==test_result[i]:\n",
    "        accuray = accuray + 1\n",
    "print(\"num of correct classification_test: \" + str(accuray))\n",
    "print(\"accuray_test: \" + str(accuray/10000.0))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
